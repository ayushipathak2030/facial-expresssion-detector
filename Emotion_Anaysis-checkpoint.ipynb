{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "kN1sqLpV1bqR",
    "outputId": "81341a62-f37d-4f3a-df18-77cb58fd8dd7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 6562
    },
    "colab_type": "code",
    "id": "jbrkxkK1LvY0",
    "outputId": "023e8d3e-4336-4388-9f9f-0887f8ecb6bc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Program Files (x86)\\anaconda 1\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Program Files (x86)\\anaconda 1\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 28709 samples, validate on 3589 samples\n",
      "Epoch 1/30\n",
      "28709/28709 [==============================] - 963s 34ms/step - loss: 1.7220 - accuracy: 0.2959 - val_loss: 1.5856 - val_accuracy: 0.3792\n",
      "Epoch 2/30\n",
      "28709/28709 [==============================] - 935s 33ms/step - loss: 1.5024 - accuracy: 0.4084 - val_loss: 1.4321 - val_accuracy: 0.4380\n",
      "Epoch 3/30\n",
      "28709/28709 [==============================] - 940s 33ms/step - loss: 1.3924 - accuracy: 0.4582 - val_loss: 1.2950 - val_accuracy: 0.5021\n",
      "Epoch 4/30\n",
      "28709/28709 [==============================] - 1841s 64ms/step - loss: 1.3348 - accuracy: 0.4875 - val_loss: 1.2671 - val_accuracy: 0.5113\n",
      "Epoch 5/30\n",
      "28709/28709 [==============================] - 937s 33ms/step - loss: 1.2904 - accuracy: 0.5067 - val_loss: 1.2578 - val_accuracy: 0.5155\n",
      "Epoch 6/30\n",
      "28709/28709 [==============================] - 964s 34ms/step - loss: 1.2545 - accuracy: 0.5175 - val_loss: 1.2252 - val_accuracy: 0.5146\n",
      "Epoch 7/30\n",
      "28709/28709 [==============================] - 967s 34ms/step - loss: 1.2237 - accuracy: 0.5311 - val_loss: 1.1967 - val_accuracy: 0.5369\n",
      "Epoch 8/30\n",
      "28709/28709 [==============================] - 941s 33ms/step - loss: 1.1985 - accuracy: 0.5397 - val_loss: 1.1918 - val_accuracy: 0.5422\n",
      "Epoch 9/30\n",
      "28709/28709 [==============================] - 934s 33ms/step - loss: 1.1738 - accuracy: 0.5521 - val_loss: 1.1850 - val_accuracy: 0.5469\n",
      "Epoch 10/30\n",
      "28709/28709 [==============================] - 832s 29ms/step - loss: 1.1489 - accuracy: 0.5632 - val_loss: 1.1759 - val_accuracy: 0.5517\n",
      "Epoch 11/30\n",
      "28709/28709 [==============================] - 743s 26ms/step - loss: 1.1312 - accuracy: 0.5673 - val_loss: 1.1528 - val_accuracy: 0.5731\n",
      "Epoch 12/30\n",
      "28709/28709 [==============================] - 715s 25ms/step - loss: 1.1160 - accuracy: 0.5755 - val_loss: 1.1819 - val_accuracy: 0.5556\n",
      "Epoch 13/30\n",
      "28709/28709 [==============================] - 699s 24ms/step - loss: 1.0917 - accuracy: 0.5800 - val_loss: 1.1671 - val_accuracy: 0.5665\n",
      "Epoch 14/30\n",
      "28709/28709 [==============================] - 731s 25ms/step - loss: 1.0781 - accuracy: 0.5885 - val_loss: 1.1580 - val_accuracy: 0.5665\n",
      "Epoch 15/30\n",
      "28709/28709 [==============================] - 680s 24ms/step - loss: 1.0586 - accuracy: 0.5944 - val_loss: 1.1651 - val_accuracy: 0.5620\n",
      "Epoch 16/30\n",
      "28709/28709 [==============================] - 748s 26ms/step - loss: 1.0401 - accuracy: 0.6038 - val_loss: 1.1618 - val_accuracy: 0.5600\n",
      "Epoch 17/30\n",
      "28709/28709 [==============================] - 770s 27ms/step - loss: 1.0228 - accuracy: 0.6078 - val_loss: 1.1539 - val_accuracy: 0.5726\n",
      "Epoch 18/30\n",
      "28709/28709 [==============================] - 1089s 38ms/step - loss: 1.0129 - accuracy: 0.6136 - val_loss: 1.1554 - val_accuracy: 0.5701\n",
      "Epoch 19/30\n",
      "28709/28709 [==============================] - 941s 33ms/step - loss: 0.9980 - accuracy: 0.6203 - val_loss: 1.1604 - val_accuracy: 0.5617\n",
      "Epoch 20/30\n",
      "28709/28709 [==============================] - 813s 28ms/step - loss: 0.9843 - accuracy: 0.6266 - val_loss: 1.1664 - val_accuracy: 0.5701\n",
      "Epoch 21/30\n",
      "28709/28709 [==============================] - 797s 28ms/step - loss: 0.9701 - accuracy: 0.6296 - val_loss: 1.1780 - val_accuracy: 0.5620\n",
      "Epoch 22/30\n",
      "28709/28709 [==============================] - 904s 31ms/step - loss: 0.9629 - accuracy: 0.6330 - val_loss: 1.1766 - val_accuracy: 0.5687\n",
      "Epoch 23/30\n",
      "28709/28709 [==============================] - 1072s 37ms/step - loss: 0.9422 - accuracy: 0.6415 - val_loss: 1.1703 - val_accuracy: 0.5695\n",
      "Epoch 24/30\n",
      "28709/28709 [==============================] - 1177s 41ms/step - loss: 0.9290 - accuracy: 0.6489 - val_loss: 1.1562 - val_accuracy: 0.5709\n",
      "Epoch 25/30\n",
      "28709/28709 [==============================] - 945s 33ms/step - loss: 0.9136 - accuracy: 0.6533 - val_loss: 1.1862 - val_accuracy: 0.5665\n",
      "Epoch 26/30\n",
      "28709/28709 [==============================] - 932s 32ms/step - loss: 0.9002 - accuracy: 0.6598 - val_loss: 1.2013 - val_accuracy: 0.5575\n",
      "Epoch 27/30\n",
      "28709/28709 [==============================] - 922s 32ms/step - loss: 0.8837 - accuracy: 0.6628 - val_loss: 1.1944 - val_accuracy: 0.5701\n",
      "Epoch 28/30\n",
      "28709/28709 [==============================] - 3012s 105ms/step - loss: 0.8725 - accuracy: 0.6692 - val_loss: 1.1762 - val_accuracy: 0.5651\n",
      "Epoch 29/30\n",
      "28709/28709 [==============================] - 1121s 39ms/step - loss: 0.8639 - accuracy: 0.6716 - val_loss: 1.1969 - val_accuracy: 0.5748\n",
      "Epoch 30/30\n",
      "28709/28709 [==============================] - 975s 34ms/step - loss: 0.8515 - accuracy: 0.6775 - val_loss: 1.2164 - val_accuracy: 0.5709\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization,AveragePooling2D\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import np_utils\n",
    "# pd.set_option('display.max_rows', 500)\n",
    "# pd.set_option('display.max_columns', 500)\n",
    "# pd.set_option('display.width', 1000)\n",
    "\n",
    "df=pd.read_csv('C:/Users/Ayushi/Downloads/fer2013.csv')\n",
    "\n",
    "# print(df.info())\n",
    "# print(df[\"Usage\"].value_counts())\n",
    "\n",
    "# print(df.head())\n",
    "X_train,train_y,X_test,test_y=[],[],[],[]\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    val=row['pixels'].split(\" \")\n",
    "    try:\n",
    "        if 'Training' in row['Usage']:\n",
    "           X_train.append(np.array(val,'float32'))\n",
    "           train_y.append(row['emotion'])\n",
    "        elif 'PublicTest' in row['Usage']:\n",
    "           X_test.append(np.array(val,'float32'))\n",
    "           test_y.append(row['emotion'])\n",
    "    except:\n",
    "        print(f\"error occured at index :{index} and row:{row}\")\n",
    "\n",
    "\n",
    "num_features = 64\n",
    "num_labels = 7\n",
    "batch_size = 64\n",
    "epochs = 30\n",
    "width, height = 48, 48\n",
    "\n",
    "\n",
    "X_train = np.array(X_train,'float32')\n",
    "train_y = np.array(train_y,'float32')\n",
    "X_test = np.array(X_test,'float32')\n",
    "test_y = np.array(test_y,'float32')\n",
    "\n",
    "train_y=np_utils.to_categorical(train_y, num_classes=num_labels)\n",
    "test_y=np_utils.to_categorical(test_y, num_classes=num_labels)\n",
    "\n",
    "#cannot produce\n",
    "#normalizing data between oand 1\n",
    "X_train -= np.mean(X_train, axis=0)\n",
    "X_train /= np.std(X_train, axis=0)\n",
    "\n",
    "X_test -= np.mean(X_test, axis=0)\n",
    "X_test /= np.std(X_test, axis=0)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 48, 48, 1)\n",
    "\n",
    "X_test = X_test.reshape(X_test.shape[0], 48, 48, 1)\n",
    "\n",
    "# print(f\"shape:{X_train.shape}\")\n",
    "##designing the cnn\n",
    "#1st convolution layer\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=(X_train.shape[1:])))\n",
    "model.add(Conv2D(64,kernel_size= (3, 3), activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#2nd convolution layer\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#3rd convolution layer\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "#fully connected neural networks\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(num_labels, activation='softmax'))\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "#Compliling the model\n",
    "model.compile(loss=categorical_crossentropy,\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#Training the model\n",
    "model.fit(X_train, train_y,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, test_y),\n",
    "          shuffle=True)\n",
    "\n",
    "\n",
    "#Saving the  model to  use it later on\n",
    "fer_json = model.to_json()\n",
    "with open(\"fer.json\", \"w\") as json_file:\n",
    "    json_file.write(fer_json)\n",
    "model.save_weights(\"fer.h5\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function destroyAllWindows>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import model_from_json\n",
    "from keras.preprocessing import image\n",
    "\n",
    "#load model\n",
    "model = model_from_json(open(r\"C:\\Users\\Ayushi\\Downloads\\Realtime-Emotion-Detection-master\\fer.json\", \"r\").read())\n",
    "#load weights\n",
    "model.load_weights(r'C:\\Users\\Ayushi\\Downloads\\Realtime-Emotion-Detection-master\\fer.h5')\n",
    "\n",
    "\n",
    "face_haar_cascade = cv2.CascadeClassifier(r'C:\\Users\\Ayushi\\Downloads\\Realtime-Emotion-Detection-master\\haarcascade_frontalface_default.xml')\n",
    "\n",
    "\n",
    "cap=cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret,test_img=cap.read()# captures frame and returns boolean value and captured image\n",
    "    if not ret:\n",
    "        continue\n",
    "    gray_img= cv2.cvtColor(test_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces_detected = face_haar_cascade.detectMultiScale(gray_img, 1.32, 5)\n",
    "\n",
    "\n",
    "    for (x,y,w,h) in faces_detected:\n",
    "        cv2.rectangle(test_img,(x,y),(x+w,y+h),(255,0,0),thickness=7)\n",
    "        roi_gray=gray_img[y:y+w,x:x+h]#cropping region of interest i.e. face area from  image\n",
    "        roi_gray=cv2.resize(roi_gray,(48,48))\n",
    "        img_pixels = image.img_to_array(roi_gray)\n",
    "        img_pixels = np.expand_dims(img_pixels, axis = 0)\n",
    "        img_pixels /= 255\n",
    "\n",
    "        predictions = model.predict(img_pixels)\n",
    "\n",
    "        #find max indexed array\n",
    "        max_index = np.argmax(predictions[0])\n",
    "\n",
    "        emotions = ('angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral')\n",
    "        predicted_emotion = emotions[max_index]\n",
    "\n",
    "        cv2.putText(test_img, predicted_emotion, (int(x), int(y)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
    "\n",
    "    resized_img = cv2.resize(test_img, (1000, 700))\n",
    "    cv2.imshow('Facial emotion analysis ',resized_img)\n",
    "\n",
    "\n",
    "\n",
    "    if cv2.waitKey(10) == ord('q'):#wait until 'q' key is pressed\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Emotion_Anaysis.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
